{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import re2 as re\n",
    "except:\n",
    "    import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlparse\n",
    "from category_encoders import TargetEncoder\n",
    "from itertools import product\n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from scipy.stats import pearsonr, spearmanr, pointbiserialr\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    validation_curve,\n",
    "    GridSearchCV,\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    accuracy_score,\n",
    "    make_scorer,\n",
    "    mean_squared_error,\n",
    ")\n",
    "from sklearn.linear_model import Lasso, ElasticNet, Ridge\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df_883 = pd.read_csv(\"all_df_883.csv\", index_col=0)\n",
    "# # JAVASCRIPT NEW CREATED FEATURES\n",
    "# new_features = all_df_883[all_df_883.columns[303:]].copy()\n",
    "# new_features.drop([\"contentname\", \"label\"], axis=1, inplace=True)\n",
    "# new_features.fillna(0, inplace=True)\n",
    "\n",
    "# ngram_train, ngram_test = train_test_split(new_features, test_size=0.2, random_state=42)\n",
    "# ngram_train.reset_index(drop=True, inplace=True)\n",
    "# ngram_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# integ_train, integ_test = train_test_split(integ_df, test_size=0.2, random_state=42)\n",
    "# integ_train.reset_index(drop=True, inplace=True)\n",
    "# integ_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# train_df = pd.concat(\n",
    "#     [\n",
    "#         integ_train[integ_train.columns[:-1]],\n",
    "#         train_url230_sg,\n",
    "#         ngram_train,\n",
    "#         integ_train[\"label\"],\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "# test_df = pd.concat(\n",
    "#     [\n",
    "#         integ_test[integ_test.columns[:-1]],\n",
    "#         test_url230_sg,\n",
    "#         ngram_test,\n",
    "#         integ_test[\"label\"],\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_indent = train_df['avg_ident'] ** -1\n",
    "# for i in range(len(avg_indent)):\n",
    "#     if avg_indent[i] == np.inf:\n",
    "#         avg_indent[i] = 0\n",
    "# train_df['avg_ident'] = avg_indent\n",
    "\n",
    "# avg_indent = test_df['avg_ident'] ** -1\n",
    "# for i in range(len(avg_indent)):\n",
    "#     if avg_indent[i] == np.inf:\n",
    "#         avg_indent[i] = 0\n",
    "# test_df['avg_ident'] = avg_indent\n",
    "\n",
    "# train_df.to_csv('all_df_883_train.csv')\n",
    "# test_df.to_csv('all_df_883_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"all_df_883_train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"all_df_883_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "filtered_feat = []\n",
    "for i in train_df.columns[2:-1]:\n",
    "    correlation, p_value = pointbiserialr(train_df.label, train_df[i])\n",
    "    if p_value > 0.1:\n",
    "        print(i)\n",
    "        print(\"Correlation coefficient:\", correlation)\n",
    "        print(\"p-value:\", p_value)\n",
    "        cnt += 1\n",
    "        filtered_feat.append(i)\n",
    "train_df.drop(filtered_feat, inplace=True, axis=1)\n",
    "print(\"Removed : \", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop([\"visit_id\", \"name\", \"label\"], axis=1)\n",
    "y = train_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, shuffle=True, test_size=0.2, random_state=42\n",
    ")  # train / vaild\n",
    "# Train a RandomForest model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "# Convert the importances into a DataFrame\n",
    "feature_importances = pd.DataFrame(\n",
    "    {\"feature\": X_train.columns.to_list(), \"importance\": importances}\n",
    ")\n",
    "print(\"feature_importances\")\n",
    "# Get permutation importances\n",
    "result = permutation_importance(\n",
    "    clf, X_valid, y_valid, n_repeats=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "print(\"result\")\n",
    "# Convert the importances into a DataFrame\n",
    "perm_importances = pd.DataFrame(\n",
    "    {\"feature\": X_train.columns.to_list(), \"importance\": result.importances_mean}\n",
    ")\n",
    "\n",
    "# Print permutation importances\n",
    "print(perm_importances)\n",
    "\n",
    "feature_importances.columns = [\"feature\", \"RFI_importance\"]\n",
    "perm_importances.columns = [\"feature\", \"PI_importance\"]\n",
    "concat = feature_importances.copy()\n",
    "concat = pd.concat([concat, perm_importances.PI_importance], axis=1)\n",
    "concat[\"RFI_PI_MEAN\"] = (concat.RFI_importance + concat.PI_importance) / 2\n",
    "concat\n",
    "concat.to_csv(\"RFI_PI_1006.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphFeatures = [  # 52\n",
    "    \"num_nodes\",\n",
    "    \"num_edges\",\n",
    "    \"nodes_div_by_edges\",\n",
    "    \"edges_div_by_nodes\",\n",
    "    \"in_degree\",\n",
    "    \"out_degree\",\n",
    "    \"in_out_degree\",\n",
    "    \"average_degree_connectivity\",\n",
    "    \"is_ancestor_script\",\n",
    "    \"ascendant_has_ad_keyword\",\n",
    "    \"descendant_of_eval_or_function\",\n",
    "    \"ascendant_script_has_eval_or_function\",\n",
    "    \"ascendant_script_has_fp_keyword\",\n",
    "    \"ascendant_script_length\",\n",
    "    \"ancestors\",\n",
    "    \"descendants\",\n",
    "    \"closeness_centrality\",\n",
    "    \"eccentricity\",\n",
    "    \"num_script_predecessors\",\n",
    "    \"num_script_successors\",\n",
    "    \"num_requests_received\",\n",
    "    \"num_redirects_sent\",\n",
    "    \"num_redirects_rec\",\n",
    "    \"max_depth_redirect\",\n",
    "    \"indirect_in_degree\",\n",
    "    \"indirect_out_degree\",\n",
    "    \"indirect_ancestors\",\n",
    "    \"indirect_descendants\",\n",
    "    \"indirect_closeness_centrality\",\n",
    "    \"indirect_average_degree_connectivity\",\n",
    "    \"indirect_eccentricity\",\n",
    "    \"indirect_mean_in_weights\",\n",
    "    \"indirect_min_in_weights\",\n",
    "    \"indirect_max_in_weights\",\n",
    "    \"indirect_mean_out_weights\",\n",
    "    \"indirect_min_out_weights\",\n",
    "    \"indirect_max_out_weights\",\n",
    "    \"num_set_get_src\",\n",
    "    \"num_set_mod_src\",\n",
    "    \"num_set_url_src\",\n",
    "    \"num_get_url_src\",\n",
    "    \"num_set_get_dst\",\n",
    "    \"num_set_mod_dst\",\n",
    "    \"num_set_url_dst\",\n",
    "    \"num_get_url_dst\",\n",
    "    \"indirect_all_in_degree\",\n",
    "    \"indirect_all_out_degree\",\n",
    "    \"indirect_all_ancestors\",\n",
    "    \"indirect_all_descendants\",\n",
    "    \"indirect_all_closeness_centrality\",\n",
    "    \"indirect_all_average_degree_connectivity\",\n",
    "    \"indirect_all_eccentricity\",\n",
    "]\n",
    "\n",
    "pi_is_zero = perm_importances.loc[\n",
    "    (perm_importances.PI_importance <= 0)\n",
    "].feature.tolist()\n",
    "X_wo_graph = X.drop(graphFeatures + pi_is_zero, axis=1)\n",
    "\n",
    "X_wo_graph = X_wo_graph[X_wo_graph.columns[:260]]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_wo_graph, y, shuffle=True, test_size=0.2, random_state=42\n",
    ")  # train / vaild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_features_to_select = 10\n",
    "step = 1\n",
    "selector = RFECV(\n",
    "    clf,\n",
    "    step=step,\n",
    "    cv=5,\n",
    "    min_features_to_select=min_features_to_select,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "print(\"RFECV\")\n",
    "\n",
    "selector = selector.fit(X_wo_graph, y)\n",
    "print(\"selector\")\n",
    "\n",
    "rfecv_support = selector.support_\n",
    "rfecv_ranking = selector.ranking_\n",
    "print(\"RFECV support:\", rfecv_support)\n",
    "print(\"RFECV ranking:\", rfecv_ranking)\n",
    "selected_perm_importance = perm_importances[rfecv_support]\n",
    "print(\n",
    "    \"Permutation importance for the selected features by RFECV:\",\n",
    "    selected_perm_importance,\n",
    ")\n",
    "\n",
    "mask = selector.get_support()\n",
    "features = np.array(X_wo_graph.columns.to_list())\n",
    "best_features = features[mask]\n",
    "\n",
    "print(\"All features: \", X_wo_graph.columns.to_list())\n",
    "print(features)\n",
    "\n",
    "print(\"Selected best: \", best_features.shape[0])\n",
    "print(features[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected best:  47\n",
    "selected_features = ['content_policy_type','url_length','is_subdomain','is_third_party'\n",
    " 'keyword_char_present','num_get_storage','num_set_storage'\n",
    " 'num_get_cookie','num_requests_sent','req_url_15','req_url_18'\n",
    " 'req_url_21','req_url_22','req_url_33','req_url_38','req_url_44'\n",
    " 'req_url_91','req_url_110','req_url_121','req_url_135','req_url_176'\n",
    " 'req_url_179','fqdn_0','fqdn_1','fqdn_3','fqdn_4','fqdn_5','fqdn_6'\n",
    " 'fqdn_7','fqdn_8','fqdn_9','fqdn_11','fqdn_12','fqdn_13','fqdn_14'\n",
    " 'fqdn_15','fqdn_16','fqdn_17','fqdn_18','fqdn_19','fqdn_22','fqdn_23'\n",
    " 'fqdn_24','fqdn_25','fqdn_26','fqdn_27','fqdn_28']\n",
    "\n",
    "importance_score = [0.9496375, 0.9512   , 0.9529375, 0.9540875, 0.954775 , 0.955175 ,\n",
    "       0.9548   , 0.9552875, 0.9552625, 0.956275 , 0.9572875, 0.9570125,\n",
    "       0.9581125, 0.9585625, 0.95925  , 0.9588125, 0.9594375, 0.959925 ,\n",
    "       0.9603125, 0.960925 , 0.9610375, 0.9614375, 0.9619125, 0.9619   ,\n",
    "       0.96175  , 0.961975 , 0.961425 , 0.9619   , 0.9616125, 0.961725 ,\n",
    "       0.9617   , 0.9616375, 0.9618875, 0.9617875, 0.962625 , 0.962425 ,\n",
    "       0.9625875, 0.9630125, 0.962375 , 0.9623625, 0.9619375, 0.9626375,\n",
    "       0.962625 , 0.96245  , 0.962675 , 0.96235  , 0.9627125, 0.962475 ,\n",
    "       0.961925 , 0.9622125, 0.9620375, 0.9618   , 0.96175  , 0.962075 ,\n",
    "       0.9614125, 0.9612125, 0.961475 , 0.960775 , 0.961075 , 0.961225 ,\n",
    "       0.9605625, 0.9610625, 0.9606875, 0.960575 , 0.9604   , 0.960525 ,\n",
    "       0.9601   , 0.9602   , 0.9604375, 0.959925 , 0.9595   , 0.9597625,\n",
    "       0.96     , 0.9596625, 0.95975  , 0.959675 , 0.95955  , 0.9596125,\n",
    "       0.9592375, 0.959825 , 0.95865  , 0.9591125, 0.9589875, 0.959425 ,\n",
    "       0.9587375, 0.9587625, 0.958775 , 0.958725 , 0.95865  , 0.958325 ,\n",
    "       0.9581125, 0.958725 , 0.9584   , 0.9585125, 0.9582625, 0.9585125,\n",
    "       0.9584375, 0.9584375, 0.9584   , 0.957575 , 0.9580875, 0.958175 ,\n",
    "       0.957875 , 0.957825 , 0.957575 , 0.9576625, 0.95785  , 0.95775  ,\n",
    "       0.95745  , 0.9576   , 0.9576375, 0.957425 , 0.9576   , 0.9576375,\n",
    "       0.957175 , 0.9580125, 0.9571375, 0.9573125, 0.9572125, 0.9572375,\n",
    "       0.95695  , 0.95705  , 0.95695  , 0.957575 , 0.957225 , 0.95715  ,\n",
    "       0.9570125, 0.957125 , 0.956925 , 0.9574125, 0.95655  , 0.95685  ,\n",
    "       0.95715  , 0.9566875, 0.9569   , 0.9562875, 0.95645  , 0.9566125,\n",
    "       0.956475 , 0.9568375, 0.9566625, 0.956175 , 0.95615  , 0.9560375,\n",
    "       0.9562625, 0.9565875, 0.95635  , 0.9564125, 0.9562625, 0.9559375,\n",
    "       0.95655  , 0.9561   , 0.956075 , 0.9561875, 0.9559875, 0.9564   ,\n",
    "       0.9556   , 0.9556   , 0.9561625, 0.956225 , 0.9558875, 0.9561   ,\n",
    "       0.95575  , 0.9557   , 0.9555625, 0.9560625, 0.955525 , 0.9556125,\n",
    "       0.955525 , 0.95525  , 0.9558875, 0.95555  , 0.95525  , 0.955975 ,\n",
    "       0.9555125, 0.9556   , 0.9555375, 0.9555375, 0.9557875, 0.955675 ,\n",
    "       0.9557   , 0.9556125, 0.95535  , 0.955075 , 0.9552   , 0.955325 ,\n",
    "       0.9552375, 0.9555625, 0.9554125, 0.954825 , 0.9554125, 0.9551375,\n",
    "       0.955375 , 0.95545  , 0.955025 , 0.955075 , 0.9547375, 0.95445  ,\n",
    "       0.9554625, 0.9552875, 0.9553   , 0.95545  , 0.9550625, 0.9548125,\n",
    "       0.9549375, 0.9548625, 0.9548125, 0.954925 , 0.955175 , 0.9544875,\n",
    "       0.9550875, 0.95495  , 0.9547125, 0.9546   , 0.95465  , 0.9547375,\n",
    "       0.9551375, 0.954825 , 0.955025 , 0.95495  , 0.954175 , 0.9547875,\n",
    "       0.9549625, 0.954375 , 0.9543375, 0.9546625, 0.9543   , 0.954975 ,\n",
    "       0.9545375, 0.95475  , 0.9543625, 0.9543625, 0.9548625, 0.95465  ,\n",
    "       0.9546   , 0.9545   , 0.954425 , 0.9544625, 0.9542875, 0.95405  ,\n",
    "       0.9542125, 0.9544875, 0.955075 , 0.95475  , 0.9543125, 0.9542   ,\n",
    "       0.9548625, 0.9544625, 0.9542625, 0.954325 , 0.954575 , 0.9541   ,\n",
    "       0.9546125, 0.9546375, 0.9543875, 0.9546375, 0.95365  , 0.9549875,\n",
    "       0.9537875, 0.9539875, 0.9544375, 0.9545625, 0.9544125, 0.953825 ,\n",
    "       0.9547   , 0.953875 , 0.95415  , 0.9543625, 0.9544625, 0.9535625,\n",
    "       0.9544625, 0.9536625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pearsonr = []\n",
    "for i in range(len(X_wo_graph.columns)):\n",
    "    for j in range(i, len(X_wo_graph.columns)):\n",
    "        if (\n",
    "            pearsonr(\n",
    "                X_wo_graph[X_wo_graph.columns[i]], X_wo_graph[X_wo_graph.columns[j]]\n",
    "            )[1]\n",
    "            >= 0.05\n",
    "        ):\n",
    "            print(\n",
    "                f\"{X_wo_graph.columns[i]}, {X_wo_graph.columns[j]} : {pearsonr(X_wo_graph[X_wo_graph.columns[i]], X_wo_graph[X_wo_graph.columns[j]])[1]}\"\n",
    "            )\n",
    "            if (X_wo_graph.columns[i].find(\"req_\") != -1) | (\n",
    "                X_wo_graph.columns[i].find(\"fqdn_\") != -1\n",
    "            ):\n",
    "                res_pearsonr.append(X_wo_graph.columns[i])\n",
    "            else:\n",
    "                res_pearsonr.append(X_wo_graph.columns[j])\n",
    "\n",
    "res_spearman = []\n",
    "\n",
    "for i in range(len(X_wo_graph.columns)):\n",
    "    for j in range(i, len(X_wo_graph.columns)):\n",
    "        if (\n",
    "            spearmanr(\n",
    "                X_wo_graph[X_wo_graph.columns[i]], X_wo_graph[X_wo_graph.columns[j]]\n",
    "            ).pvalue\n",
    "            >= 0.05\n",
    "        ):\n",
    "            print(\n",
    "                f\"{X_wo_graph.columns[i]}, {X_wo_graph.columns[j]} : {spearmanr(X_wo_graph[X_wo_graph.columns[i]], X_wo_graph[X_wo_graph.columns[j]]).pvalue}\"\n",
    "            )\n",
    "            if (X_wo_graph.columns[i].find(\"req_\") != -1) | (\n",
    "                X_wo_graph.columns[i].find(\"fqdn_\") != -1\n",
    "            ):\n",
    "                res_spearman.append(X_wo_graph.columns[i])\n",
    "            else:\n",
    "                res_spearman.append(X_wo_graph.columns[j])\n",
    "\n",
    "corr_list = pd.Series(res_pearsonr + res_spearman).unique()\n",
    "corr_list\n",
    "\n",
    "print(\n",
    "    f\"Final Selected Features : \\n {[i for i in list(features[mask]) if i not in corr_list]} \"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webtrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
